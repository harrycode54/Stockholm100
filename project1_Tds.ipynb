{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJzYZVYGpztz",
    "outputId": "f908de16-14b7-4152-fd07-96019e67d6b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created: repositories.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def get_repositories(token, username, per_page=100):\n",
    "    headers = {'Authorization': f'token {token}'}\n",
    "    url = f'https://api.github.com/users/{username}/repos'\n",
    "    repos = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        params = {'per_page': per_page, 'page': page}\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            data = response.json()\n",
    "\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            for repo in data:\n",
    "                license_name = None\n",
    "                if repo.get('license') is not None:\n",
    "                    license_name = repo.get('license', {}).get('name', None)\n",
    "\n",
    "                repo_data = {\n",
    "                    'login': username,  # Add user login from username\n",
    "                    'full_name': repo['full_name'],\n",
    "                    'created_at': repo['created_at'],\n",
    "                    'stargazers_count': repo['stargazers_count'],\n",
    "                    'watchers_count': repo['watchers_count'],\n",
    "                    'language': repo.get('language', None),\n",
    "                    'has_projects': repo.get('has_projects', False),\n",
    "                    'has_wiki': repo.get('has_wiki', False),\n",
    "                    'license_name': license_name\n",
    "                }\n",
    "\n",
    "                repos.append(repo_data)\n",
    "\n",
    "            if len(repos) >= 500:\n",
    "                break  # Reached desired limit\n",
    "\n",
    "            page += 1\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching repos for {username}: {e}\")\n",
    "            break\n",
    "\n",
    "    return repos\n",
    "\n",
    "def write_to_csv(data, filename='repositories.csv'):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        fieldnames = ['login', 'full_name', 'created_at', 'stargazers_count', 'watchers_count', 'language', 'has_projects', 'has_wiki', 'license_name']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"CSV file created: {filename}\")\n",
    "\n",
    "def main():\n",
    "    token = 'My_token'#removed my token for security purposes\n",
    "\n",
    "    # Assuming users.csv is accessible via the provided link\n",
    "    # user_data_url = 'https://drive.google.com/file/d/1uevdg9JbkYlxVwXdbxIDl-7MfpjkyZNA/view?usp=sharing'\n",
    "    user_data = []\n",
    "\n",
    "    # Download users.csv (implement your preferred download method)\n",
    "    # ... (download logic)\n",
    "\n",
    "    # Read user data from downloaded users.csv\n",
    "    with open('stockholm_users.csv', mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            user_data.append(row)\n",
    "\n",
    "    repos_data = []\n",
    "    for user in user_data:\n",
    "        repos = get_repositories(token, user['login'])\n",
    "        repos_data.extend(repos[:500])  # Limit to 500 repositories\n",
    "\n",
    "    write_to_csv(repos_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AreHglxH7bUy",
    "outputId": "d9f8d292-05ed-46ff-f6c9-439a55eeb0c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kallepersson', 'pirelenito', 'dalen', 'torkelo', 'possan']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "def get_earliest_users(filename):\n",
    "    \"\"\"Reads a CSV file, sorts users by creation date, and returns the top 5 earliest users from Stockholm.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 5 earliest users' logins.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        users = []\n",
    "        for row in reader:\n",
    "            if row['location'] == 'Stockholm':\n",
    "                user_data = {\n",
    "                    'login': row['login'],\n",
    "                    'created_at': datetime.datetime.strptime(row['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                }\n",
    "                users.append(user_data)\n",
    "\n",
    "    # Sort users by creation date\n",
    "    users.sort(key=lambda x: x['created_at'])\n",
    "\n",
    "    # Return the top 5 earliest users' logins\n",
    "    return [user['login'] for user in users[:5]]\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'stockholm_users.csv'\n",
    "earliest_users = get_earliest_users(filename)\n",
    "\n",
    "print(earliest_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-VEOF7vBiIG",
    "outputId": "d4017f5d-5366-41ea-f022-daa775589046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MIT License', 'Apache License 2.0', 'Other']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def get_top_licenses(filename):\n",
    "    \"\"\"Reads a CSV file, counts license occurrences, and returns the top 3 most popular licenses.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 3 most popular license names.\n",
    "    \"\"\"\n",
    "\n",
    "    license_counts = Counter()\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            license_name = row['license_name']\n",
    "            if license_name:\n",
    "                license_counts[license_name] += 1\n",
    "\n",
    "    # Get the top 3 most common licenses\n",
    "    top_licenses = license_counts.most_common(3)\n",
    "    return [license[0] for license in top_licenses]\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "top_licenses = get_top_licenses(filename)\n",
    "\n",
    "print(top_licenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9NRTk3AgCQ4O",
    "outputId": "2ba2f48e-4c83-47e4-b0cd-db8d885bea20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kallepersson', 'pirelenito', 'dalen', 'torkelo', 'possan']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "def get_earliest_users(filename):\n",
    "    \"\"\"Reads a CSV file, sorts users by creation date, and returns the top 5 earliest users from Stockholm.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 5 earliest users' logins.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        users = []\n",
    "        for row in reader:\n",
    "            if row['location'] == 'Stockholm':\n",
    "                user_data = {\n",
    "                    'login': row['login'],\n",
    "                    'created_at': datetime.datetime.strptime(row['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                }\n",
    "                users.append(user_data)\n",
    "\n",
    "    # Sort users by creation date\n",
    "    users.sort(key=lambda x: x['created_at'])\n",
    "\n",
    "    # Return the top 5 earliest users' logins\n",
    "    return [user['login'] for user in users[:5]]\n",
    "\n",
    "# Assuming 'stockholm_users.csv' is in the same directory\n",
    "filename = 'stockholm_users.csv'\n",
    "earliest_users = get_earliest_users(filename)\n",
    "\n",
    "print(earliest_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_m31WK1GeUP",
    "outputId": "2b080d03-fc7c-467d-af42-f847583ae092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPOTIFY\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_common_company(filename):\n",
    "    \"\"\"Reads a CSV file, counts company occurrences, and returns the most common company.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The most common company name.\n",
    "    \"\"\"\n",
    "\n",
    "    company_counts = Counter()\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            company = row['company']\n",
    "            if company:\n",
    "                company_counts[company] += 1\n",
    "\n",
    "    # Get the most common company\n",
    "    most_common_company, _ = company_counts.most_common(1)[0]\n",
    "    return most_common_company\n",
    "\n",
    "# Assuming 'stockholm_users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "most_common_company = get_most_common_company(filename)\n",
    "\n",
    "print(most_common_company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOWbRqjdHP9f",
    "outputId": "88612e20-a6de-400a-a3a6-9c5291c93d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JavaScript\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_popular_language(filename):\n",
    "    \"\"\"Reads a CSV file, counts language occurrences, and returns the most popular language.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The most popular language name.\n",
    "    \"\"\"\n",
    "\n",
    "    language_counts = Counter()\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            language = row['language']\n",
    "            if language:\n",
    "                language_counts[language] += 1\n",
    "\n",
    "    # Get the most common language\n",
    "    most_common_language, _ = language_counts.most_common(1)[0]\n",
    "    return most_common_language\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "most_popular_language = get_most_popular_language(filename)\n",
    "\n",
    "print(most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kg6n1ikBJw5f",
    "outputId": "d616ee41-8b63-4d99-e0d8-b29ac55cd299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAML\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_language_with_highest_avg_stars(filename):\n",
    "    \"\"\"Reads a CSV file, calculates the average stars per language, and returns the language with the highest average.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The language with the highest average stars per repository.\n",
    "    \"\"\"\n",
    "\n",
    "    language_stars = {}\n",
    "    language_counts = {}\n",
    "\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            language = row['language']\n",
    "            stars = int(row['stargazers_count'])\n",
    "\n",
    "            if language:\n",
    "                language_stars[language] = language_stars.get(language, 0) + stars\n",
    "                language_counts[language] = language_counts.get(language, 0) + 1\n",
    "\n",
    "    # Calculate average stars per language\n",
    "    language_avg_stars = {}\n",
    "    for language, total_stars in language_stars.items():\n",
    "        count = language_counts[language]\n",
    "        avg_stars = total_stars / count\n",
    "        language_avg_stars[language] = avg_stars\n",
    "\n",
    "    # Find the language with the highest average stars\n",
    "    max_avg_language = max(language_avg_stars, key=language_avg_stars.get)\n",
    "    return max_avg_language\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "most_popular_language = get_language_with_highest_avg_stars(filename)\n",
    "\n",
    "print(most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRcRTQzyK0GP",
    "outputId": "a8fc6e6c-3f34-4417-b055-ceca7a907120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeScript\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "def get_second_most_popular_language_after_2020(filename):\n",
    "    \"\"\"Reads a CSV file, counts language occurrences for users who joined after 2020, and returns the second most popular language.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The second most popular language name.\n",
    "    \"\"\"\n",
    "\n",
    "    language_counts = Counter()\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            created_at = datetime.strptime(row['created_at'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "            if created_at.year > 2020:\n",
    "                language = row['language']\n",
    "                if language:\n",
    "                    language_counts[language] += 1\n",
    "\n",
    "    # Get the top 2 most common languages\n",
    "    top_languages = language_counts.most_common(2)\n",
    "\n",
    "    # Return the second most common language\n",
    "    return top_languages[1][0]\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "second_most_popular_language = get_second_most_popular_language_after_2020(filename)\n",
    "\n",
    "print(second_most_popular_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQwmkOkNLLKn",
    "outputId": "0282d10f-933e-4f21-a1d3-8f18364e63cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spotify', 'Mojang', 'fornwall', 'joearms', 'EmbarkStudios']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_top_leaders(filename):\n",
    "    \"\"\"Reads a CSV file, calculates leader strength for each user, and returns the top 5 leaders.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 5 leaders' logins.\n",
    "    \"\"\"\n",
    "\n",
    "    users = []\n",
    "    with open(filename, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            user_data = {\n",
    "                'login': row['login'],\n",
    "                'followers': int(row['followers']),\n",
    "                'following': int(row['following']),\n",
    "            }\n",
    "            users.append(user_data)\n",
    "\n",
    "    # Calculate leader strength for each user\n",
    "    for user in users:\n",
    "        user['leader_strength'] = user['followers'] / (1 + user['following'])\n",
    "\n",
    "    # Sort users by leader strength in descending order\n",
    "    users.sort(key=lambda x: x['leader_strength'], reverse=True)\n",
    "\n",
    "    # Return the top 5 leaders' logins\n",
    "    return [user['login'] for user in users[:5]]\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "top_leaders = get_top_leaders(filename)\n",
    "\n",
    "print(top_leaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mx9iTDpMMdh_",
    "outputId": "d27a92c8-8688-4a16-a675-1b5661c36771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between followers and public repositories: 0.150284414318553\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_correlation(filename):\n",
    "    \"\"\"Reads a CSV file, calculates the correlation between followers and public repositories, and prints the result.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Filter for Stockholm users\n",
    "    df = df[df['location'] == 'Stockholm']\n",
    "\n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = df['followers'].corr(df['public_repos'])\n",
    "\n",
    "    print(\"Correlation between followers and public repositories:\", correlation)\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "calculate_correlation(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FT9u3CD_NX1q",
    "outputId": "6bd4c309-346f-4927-b957-3785426c5f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between followers and public repositories: 0.30\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def calculate_correlation(followers, public_repos):\n",
    "  \"\"\"\n",
    "  Calculates the Pearson correlation coefficient between two lists of data.\n",
    "\n",
    "  Args:\n",
    "      followers: A list of follower counts for each user.\n",
    "      public_repos: A list of public repository counts for each user.\n",
    "\n",
    "  Returns:\n",
    "      The Pearson correlation coefficient between the two lists.\n",
    "  \"\"\"\n",
    "\n",
    "  if len(followers) != len(public_repos):\n",
    "    raise ValueError(\"Lists must be of the same length\")\n",
    "\n",
    "  n = len(followers)\n",
    "  sum_followers = sum(followers)\n",
    "  sum_repos = sum(public_repos)\n",
    "  sum_followers_squared = sum([x**2 for x in followers])\n",
    "  sum_repos_squared = sum([x**2 for x in public_repos])\n",
    "  product_sum = sum([followers[i] * public_repos[i] for i in range(n)])\n",
    "\n",
    "  # Calculate the numerator and denominator for the correlation coefficient\n",
    "  numerator = product_sum - (sum_followers * sum_repos) / n\n",
    "  denominator = (\n",
    "      ((sum_followers_squared - (sum_followers**2) / n) * (sum_repos_squared - (sum_repos**2) / n))\n",
    "      **0.5\n",
    "  )\n",
    "\n",
    "  # Handle the case where the denominator is close to zero (avoid division by zero)\n",
    "  if abs(denominator) < 1e-10:\n",
    "    return 0.0\n",
    "\n",
    "  # Calculate the correlation coefficient\n",
    "  correlation = numerator / denominator\n",
    "  return correlation\n",
    "\n",
    "# Simulate some data for users in Stockholm\n",
    "followers = [random.randint(100, 10000) for _ in range(100)]\n",
    "public_repos = [random.randint(1, 100) for _ in range(100)]\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation = calculate_correlation(followers, public_repos)\n",
    "\n",
    "print(f\"Correlation between followers and public repositories: {correlation:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mcpU1uhQNbFv",
    "outputId": "1e57afd6-f3cc-44c7-cdb4-9715a0fa55c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between followers and public repositories: 0.03322019270996551\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_correlation(filename):\n",
    "    \"\"\"Reads a CSV file, calculates the correlation between followers and public repositories, and prints the result.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Filter for Stockholm users\n",
    "    # df = df[df['location'] == 'Stockholm']\n",
    "\n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = df['followers'].corr(df['public_repos'])\n",
    "\n",
    "    print(\"Correlation between followers and public repositories:\", correlation)\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'stockholm_users.csv'\n",
    "calculate_correlation(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "la71WB6fN8AQ",
    "outputId": "b1f170d5-7075-4e29-af9c-615d3d742135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between followers and public repositories: 0.15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_correlation(filename):\n",
    "    \"\"\"Calculates the correlation between followers and public repositories for Stockholm users.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The correlation coefficient.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Filter for Stockholm users\n",
    "    df_stockholm = df[df['location'] == 'Stockholm']\n",
    "\n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = df_stockholm['followers'].corr(df_stockholm['public_repos'])\n",
    "\n",
    "    return correlation\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "correlation_coefficient = calculate_correlation(filename)\n",
    "\n",
    "print(\"Correlation between followers and public repositories:\", round(correlation_coefficient, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtB8oPGuOopH",
    "outputId": "881c65fa-cc25-471e-f7cc-685d22667d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on repos (all users): 0.217\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def calculate_regression_slope(filename):\n",
    "    \"\"\"Calculates the regression slope of followers on public repositories for all users.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The regression slope.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Perform linear regression on all users (no filtering)\n",
    "    X = df[['public_repos']]  # Select 'public_repos' for all users\n",
    "    y = df['followers']      # Select 'followers' for all users\n",
    "    X = sm.add_constant(X)    # Add a constant term\n",
    "    model = sm.OLS(y, X).fit() # Fit the regression model\n",
    "\n",
    "    # Extract the slope coefficient\n",
    "    slope = model.params['public_repos']\n",
    "\n",
    "    return slope\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "slope = calculate_regression_slope(filename)\n",
    "\n",
    "print(\"Regression slope of followers on repos (all users):\", round(slope, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAsYKLUARYCg",
    "outputId": "96fdbc49-6b0a-48a1-e106-ab7a4aec7fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mange', 'kallepersson', 'fesplugas', 'etnt', 'pirelenito']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_earliest_users(filename):\n",
    "    \"\"\"Gets the 5 earliest registered GitHub users.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 5 earliest users' logins.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Sort the DataFrame by the 'created_at' column in ascending order\n",
    "    df_sorted = df.sort_values(by='created_at')\n",
    "\n",
    "    # Get the top 5 earliest users' logins\n",
    "    top_5_earliest_users = df_sorted['login'].head(5).tolist()\n",
    "\n",
    "    return top_5_earliest_users\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "earliest_users = get_earliest_users(filename)\n",
    "\n",
    "print(earliest_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsFDWxuBS6SA",
    "outputId": "404f4bb4-15dd-4f8b-da64-8196b285fdcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between projects and wikis: 0.374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def analyze_projects_and_wikis(filename):\n",
    "    \"\"\"Calculates the correlation between projects and wikis.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The correlation coefficient.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df['has_projects'], df['has_wiki'])\n",
    "\n",
    "    # Calculate the chi-square statistic and p-value\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Calculate the correlation using the chi-square statistic\n",
    "    correlation = np.sqrt(chi2 / (len(df) - 1))\n",
    "\n",
    "    return correlation\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "correlation = analyze_projects_and_wikis(filename)\n",
    "\n",
    "print(\"Correlation between projects and wikis:\", round(correlation, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jQhciBWTPzg",
    "outputId": "b38ed1f1-e17a-4809-d44d-966c9916bb11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between projects and wikis: 0.37394896700150726\n",
      "has_wiki      False  True \n",
      "has_projects              \n",
      "False          1072     49\n",
      "True           5060  29186\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency # Import the missing function\n",
    "\n",
    "def analyze_projects_and_wikis(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df['has_projects'], df['has_wiki'])\n",
    "\n",
    "    # Calculate the correlation using the chi-square test\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    correlation = np.sqrt(chi2 / (len(df) - 1))\n",
    "\n",
    "    print(\"Correlation between projects and wikis:\", correlation)\n",
    "\n",
    "    # Analyze the contingency table\n",
    "    print(contingency_table)\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "analyze_projects_and_wikis(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XuDncUY-Vw2w",
    "outputId": "efa397e5-26f2-4107-b73b-50d65d1510f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on bio word count: 2.079\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def analyze_bio_length_and_followers(filename):\n",
    "    \"\"\"Analyzes the relationship between bio length and followers.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The regression slope of followers on bio word count.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Calculate the word count for each bio\n",
    "    df['bio_word_count'] = df['bio'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    # Perform linear regression\n",
    "    X = df[['bio_word_count']]\n",
    "    y = df['followers']\n",
    "    X = sm.add_constant(X)  # Add a constant term\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Extract the slope coefficient\n",
    "    slope = model.params['bio_word_count']\n",
    "\n",
    "    return slope\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "slope = analyze_bio_length_and_followers(filename)\n",
    "\n",
    "print(\"Regression slope of followers on bio word count:\", round(slope, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6csAuQAXoZi",
    "outputId": "0e86c409-d35f-49d7-ec30-c9ce6b2160ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on bio word count: 2.079\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def analyze_bio_length_and_followers(filename):\n",
    "    \"\"\"Analyzes the relationship between bio length and followers.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The regression slope of followers on bio word count.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Calculate the word count for each bio\n",
    "    df['bio_word_count'] = df['bio'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    # Perform linear regression\n",
    "    X = df[['bio_word_count']]\n",
    "    y = df['followers']\n",
    "    X = sm.add_constant(X)  # Add a constant term\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Extract the slope coefficient\n",
    "    slope = model.params['bio_word_count']\n",
    "\n",
    "    return slope\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "slope = analyze_bio_length_and_followers(filename)\n",
    "\n",
    "print(\"Regression slope of followers on bio word count:\", round(slope, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdE4dfn_X5FY",
    "outputId": "26a00bf9-3e2e-4b7b-fc62-07f1bae04ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression slope of followers on bio word count: 6.574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def analyze_bio_length_and_followers(filename):\n",
    "    \"\"\"Analyzes the relationship between bio length and followers for users with bios.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The regression slope of followers on bio word count.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Filter out users without bios\n",
    "    df = df[df['bio'].notnull()]\n",
    "\n",
    "    # Calculate the word count for each bio\n",
    "    df['bio_word_count'] = df['bio'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "    # Perform linear regression\n",
    "    X = df[['bio_word_count']]\n",
    "    y = df['followers']\n",
    "    X = sm.add_constant(X)  # Add a constant term\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # Extract the slope coefficient\n",
    "    slope = model.params['bio_word_count']\n",
    "\n",
    "    return slope\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "slope = analyze_bio_length_and_followers(filename)\n",
    "\n",
    "print(\"Regression slope of followers on bio word count:\", round(slope, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BA4JAyH8aQT0",
    "outputId": "27771468-1ad3-4929-f1ef-261ff223f12d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HaraldNordgren', 'Nyholm', 'lydell', 'LinusU', 'leostera']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def get_top_weekend_contributors(filename):\n",
    "    \"\"\"Identifies the top 5 users who created the most repositories on weekends.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        A list of the top 5 users' logins.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Convert 'created_at' to datetime objects\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "    # Determine if the repository was created on a weekend\n",
    "    df['is_weekend'] = df['created_at'].dt.weekday.isin([5, 6])\n",
    "\n",
    "    # Group by user and count the number of weekend repositories\n",
    "    weekend_repos = df[df['is_weekend']].groupby('login').size()\n",
    "\n",
    "    # Sort the results and get the top 5\n",
    "    top_contributors = weekend_repos.sort_values(ascending=False).head(5)\n",
    "\n",
    "    return top_contributors.index.tolist()\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "top_weekend_contributors = get_top_weekend_contributors(filename)\n",
    "\n",
    "print(top_weekend_contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uSSNqH0bSap",
    "outputId": "5989ab94-c3a3-47ce-c6d2-58d39a62a943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in average following between hireable and non-hireable users: 48.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-70-f8feb92690c0>:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['hireable'] = df['hireable'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_hireable_following(filename):\n",
    "    \"\"\"Compares the average 'following' for hireable and non-hireable users.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The difference in average 'following' between hireable and non-hireable users.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Assuming 'hireable' might have missing values, fill them with False\n",
    "    df['hireable'] = df['hireable'].fillna(False)\n",
    "\n",
    "    # Assuming 'hireable' is a boolean column\n",
    "    hireable_avg_following = df[df['hireable']]['following'].mean()\n",
    "    non_hireable_avg_following = df[~df['hireable']]['following'].mean()\n",
    "\n",
    "    return round(hireable_avg_following - non_hireable_avg_following, 3)\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "following_difference = compare_hireable_following(filename)\n",
    "\n",
    "print(\"Difference in average following between hireable and non-hireable users:\", following_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nbB1RbTbpx5",
    "outputId": "94b17eba-aeaa-42f9-cfec-aa5a923b9c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Persson', 'Gustafsson']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def get_most_common_surname(filename):\n",
    "    \"\"\"Gets the most common surname among users.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The most common surname(s).\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Extract the last name from the 'name' column\n",
    "    df['surname'] = df['name'].apply(lambda x: x.strip().split()[-1] if isinstance(x, str) else None)\n",
    "\n",
    "    # Count the occurrences of each surname\n",
    "    surname_counts = Counter(df['surname'].dropna())\n",
    "\n",
    "    # Get the most common surnames\n",
    "    most_common_surnames = [surname for surname, count in surname_counts.most_common() if count == surname_counts.most_common(1)[0][1]]\n",
    "\n",
    "    return most_common_surnames\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "most_common_surnames = get_most_common_surname(filename)\n",
    "\n",
    "print(most_common_surnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vMYe8YVc4Ra",
    "outputId": "0eb48d18-e44e-446b-e7b2-472f809d7d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between projects and wikis: 0.374\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def analyze_projects_and_wikis(filename):\n",
    "    \"\"\"Calculates the correlation between projects and wikis.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The correlation coefficient.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df['has_projects'], df['has_wiki'])\n",
    "\n",
    "    # Calculate the chi-square statistic and p-value\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Calculate the correlation using the chi-square statistic\n",
    "    correlation = np.sqrt(chi2 / (len(df) - 1))\n",
    "\n",
    "    return correlation\n",
    "\n",
    "# Assuming 'repositories.csv' is in the same directory\n",
    "filename = 'repositories.csv'\n",
    "correlation = analyze_projects_and_wikis(filename)\n",
    "\n",
    "print(\"Correlation between projects and wikis:\", round(correlation, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjdPQMzJexpL",
    "outputId": "f5f27548-167b-4584-f2b3-4df84d823a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in average following between hireable and non-hireable users: 48.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-f8feb92690c0>:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['hireable'] = df['hireable'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compare_hireable_following(filename):\n",
    "    \"\"\"Compares the average 'following' for hireable and non-hireable users.\n",
    "\n",
    "    Args:\n",
    "        filename: The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        The difference in average 'following' between hireable and non-hireable users.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Assuming 'hireable' might have missing values, fill them with False\n",
    "    df['hireable'] = df['hireable'].fillna(False)\n",
    "\n",
    "    # Assuming 'hireable' is a boolean column\n",
    "    hireable_avg_following = df[df['hireable']]['following'].mean()\n",
    "    non_hireable_avg_following = df[~df['hireable']]['following'].mean()\n",
    "\n",
    "    return round(hireable_avg_following - non_hireable_avg_following, 3)\n",
    "\n",
    "# Assuming 'users.csv' is in the same directory\n",
    "filename = 'users.csv'\n",
    "following_difference = compare_hireable_following(filename)\n",
    "\n",
    "print(\"Difference in average following between hireable and non-hireable users:\", following_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGdi0K6Je7F5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
